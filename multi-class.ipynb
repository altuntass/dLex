{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout, Flatten,Dense,Activation\n",
    "from keras.layers.convolutional import Conv2D,MaxPooling2D\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=8\n",
    "img_width,img_height=160,160\n",
    "batch_size=32\n",
    "\n",
    "nb_filters1=32\n",
    "nb_filters2=64\n",
    "\n",
    "conv1_size=3\n",
    "conv2_size=2\n",
    "\n",
    "num_classes=5\n",
    "lr=0.0004\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path='training_set'\n",
    "validation_data_path='test_set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(filters=nb_filters1,kernel_size=(conv1_size,conv1_size),padding='same',input_shape=(img_width,img_height,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=nb_filters2,kernel_size=(conv2_size,conv2_size),padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=256,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=num_classes,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=optimizers.Adam(lr=lr),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1432 images belonging to 5 classes.\n",
      "Found 115 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator=train_datagen.flow_from_directory(\n",
    "    train_data_path,\n",
    "    target_size=(img_height,img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator=test_datagen.flow_from_directory(\n",
    "        validation_data_path,\n",
    "        target_size=(img_height,img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_epoch=1432\n",
    "validation_steps=115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "44/44 [==============================] - 14s 315ms/step - loss: 0.4469 - accuracy: 0.8366 - val_loss: 0.5600 - val_accuracy: 0.7476\n",
      "Epoch 2/8\n",
      "44/44 [==============================] - 14s 317ms/step - loss: 0.4130 - accuracy: 0.8542 - val_loss: 0.7387 - val_accuracy: 0.7560\n",
      "Epoch 3/8\n",
      "44/44 [==============================] - 14s 311ms/step - loss: 0.3963 - accuracy: 0.8507 - val_loss: 0.7391 - val_accuracy: 0.7826\n",
      "Epoch 4/8\n",
      "44/44 [==============================] - 14s 308ms/step - loss: 0.3858 - accuracy: 0.8621 - val_loss: 0.3701 - val_accuracy: 0.7563\n",
      "Epoch 5/8\n",
      "44/44 [==============================] - 13s 305ms/step - loss: 0.3507 - accuracy: 0.8679 - val_loss: 0.7819 - val_accuracy: 0.7738\n",
      "Epoch 6/8\n",
      "44/44 [==============================] - 13s 304ms/step - loss: 0.3454 - accuracy: 0.8771 - val_loss: 0.6284 - val_accuracy: 0.7660\n",
      "Epoch 7/8\n",
      "44/44 [==============================] - 13s 299ms/step - loss: 0.2737 - accuracy: 0.9059 - val_loss: 0.5739 - val_accuracy: 0.7651\n",
      "Epoch 8/8\n",
      "44/44 [==============================] - 13s 294ms/step - loss: 0.2874 - accuracy: 0.8900 - val_loss: 0.6754 - val_accuracy: 0.7560\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_generator,\n",
    "                    epochs=epochs,\n",
    "                   validation_data=validation_generator,\n",
    "                   validation_steps=validation_steps,\n",
    "                   steps_per_epoch=44)\n",
    "\n",
    "target_dir='./models/'\n",
    "\n",
    "if not os.path.exists(target_dir):\n",
    "    os.mkdir(target_dir)\n",
    "    \n",
    "model.save('./models/model_celebs.h5')\n",
    "model.save_weights('./models/weights_celebs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import load_img,img_to_array\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width,img_height=160,160\n",
    "model_path='./models/model_celebs.h5'\n",
    "model_weights_path='./models/weights_celebs.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(file):\n",
    "    x=load_img(file,target_size=(img_width,img_height))\n",
    "    x=img_to_array(x)\n",
    "    x=np.expand_dims(x,axis=0)\n",
    "    \n",
    "    array=model.predict(x)\n",
    "    result=array[0]\n",
    "    answer=np.argmax(result)\n",
    "    \n",
    "    if answer==0:\n",
    "        print(\"Label is : Angelina Jolie\")\n",
    "    if answer==1:\n",
    "        print(\"Label is : Obama\")\n",
    "    if answer==2:\n",
    "        print(\"Label is : Donald Trump\")\n",
    "    if answer==3:\n",
    "        print(\"Label is : Gal Gadot\")\n",
    "    if answer==4:\n",
    "        print(\"Label is :  Rihanna\")\n",
    "        \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label is : Donald Trump\n"
     ]
    }
   ],
   "source": [
    "my_pred=predict('trm.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
